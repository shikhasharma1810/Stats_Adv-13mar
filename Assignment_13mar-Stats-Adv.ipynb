{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fa887-2090-4ef2-a212-b6254ac9db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fff9c-9006-450b-843b-b0ca76de7b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of Variance (ANOVA) relies on the following main assumptions for its results to be valid:\n",
    "    \n",
    "1. Normality of sampling distribution of means: The data within each group should be normally \n",
    "distributed, resembling a bell-shaped curve with few outliers.\n",
    "\n",
    "2. Homogeneity of variance : The variance of the data within each group should be equal. \n",
    "\n",
    "3. Absence of outliers: Outlying score need to be removed from dataset.\n",
    "\n",
    "4. Independence : The observations within each group should be independent and random. This means the same person\n",
    "shouldn't be measured multiple times. \n",
    "\n",
    "Violations:\n",
    "    \n",
    "1. Non-normality: Violating the normality assumption can increase the chance of a false positive result.\n",
    "However, ANOVA is generally robust to moderate deviations from normality.\n",
    " \n",
    "2. Unequal variances: Violating the homogeneity of variance assumption can be more impactful, especially\n",
    "when sample sizes are unequal. This can lead to false positives or negatives.\n",
    "\n",
    "3. Non-independence: Lack of independence can occur within or between samples. For example, if the \n",
    "same person is measured multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3030823-7fcf-4b0d-ae9a-cd8d000c08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbc63a-77a6-423d-b227-ecbfad414932",
   "metadata": {},
   "outputs": [],
   "source": [
    "One-way ANOVA: Used to compare one factor with atleast 2 levels and the levels are independent. \n",
    "For example, comparing the medication to decrease headache under 3 conditions(10mg, 20mg, 30mg).\n",
    "\n",
    "Repeated measures ANOVA: Used to compare one factor with atleast 2 levels and the levels are dependent. \n",
    "For example, comparing the running finish times of a runner on different weekdays.\n",
    "\n",
    "Factorial ANOVA: Used to examine 2 or more factors(each of which with atleast 2 levels) and levels \n",
    "canbe either dependent and independent.\n",
    "For example, comparing the race finish times of runners on different weekdays and belonging to different gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf27e7-5a42-477d-99ce-ed4dab3de23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e291724-14f9-4ac2-8433-d82bcafe3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the \n",
    "variance within a group.\n",
    "\n",
    "The total variation present in a set of data may be partitioned into a number of non-overlapping\n",
    "components as per the nature of the classification. The systematic procedure to achieve this is \n",
    "called Analysis of Variance (ANOVA). With the help of such a partitioning, some testing of \n",
    "hypothesis may be performed.\n",
    "\n",
    "Partitioning variance in Analysis of Variance (ANOVA) is important because it helps researchers understand\n",
    "the relationships between different factors and their contributions to the variability of a dependent\n",
    "variable. This information can help researchers make informed decisions based on their results. \n",
    "\n",
    "This partitioning can be done based on the nature of the classification and can be used to perform\n",
    "hypothesis testing. For example, ANOVA can be used to determine if there are statistically significant\n",
    "differences in mean test scores across different teaching methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da3fc7-6fc3-42a9-8894-2dfb09effdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2a4c7-584b-402f-aafe-e3f554e5b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Sum of Squares Total (SST): The sum of squared differences between individual data points (yi) and\n",
    "the mean of the response variable (y).\n",
    "SST = Σ(yi – y)2\n",
    "\n",
    "2. Sum of Squares Error (SSE): The sum of squared differences between predicted data points (ŷi) and \n",
    "observed data points (yi).\n",
    "SSE = Σ(ŷi – yi)2\n",
    "\n",
    "3. Sum of Squares Regression (SSR): The sum of squared differences between predicted data points (ŷi) and\n",
    "the mean of the response variable(y).\n",
    "SSR = Σ(ŷi – ybar)2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201bd50f-a184-4a1e-8dca-77263d37fb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 331.07488479262696\n",
      "SSR: 917.4751152073725\n",
      "SST: 1248.5499999999995\n"
     ]
    }
   ],
   "source": [
    "# Example:-\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.DataFrame({'hours': [1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 6, 7, 7, 8],\n",
    "                   'score': [68, 76, 74, 80, 76, 78, 81, 84, 86, 83, 88, 85, 89, 94, 93, 94, 96, 89, 92, 97]})\n",
    "\n",
    "#define response variable\n",
    "y = df['score']\n",
    "\n",
    "#define predictor variable\n",
    "x = df[['hours']]\n",
    "\n",
    "#add constant to predictor variables, add a column of ones to an array.\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model using Ordinary Least Squares(OLS)\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "#calculate sse\n",
    "sse = np.sum((model.fittedvalues - df.score)**2)\n",
    "print('SSE:',sse)\n",
    "\n",
    "#calculate ssr\n",
    "ssr = np.sum((model.fittedvalues - df.score.mean())**2)\n",
    "print('SSR:',ssr)\n",
    "\n",
    "#calculate sst\n",
    "sst = ssr + sse\n",
    "print('SST:',sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2699af3-75b7-4ad2-9aab-af86b5546a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da5ba1-ef28-4348-95b1-ceadc640da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can calculate the main effects & interaction effects using python.\n",
    "\n",
    "For example, \n",
    "\n",
    "The factors are as follows: \n",
    "1. Water: how frequently each plant was watered- daily or weekly\n",
    "2. Sun: how much sunlight exposure each plant received- low, medium, or high\n",
    "3. Height: the height of each plant (in inches) after two months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a174731-ae28-4f07-9740-27671cb731dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     water   sun  height\n",
      "0    daily   low       6\n",
      "1    daily   low       6\n",
      "2    daily   low       6\n",
      "3    daily   low       5\n",
      "4    daily   low       6\n",
      "5    daily   med       5\n",
      "6    daily   med       5\n",
      "7    daily   med       6\n",
      "8    daily   med       4\n",
      "9    daily   med       5\n",
      "10   daily  high       6\n",
      "11   daily  high       6\n",
      "12   daily  high       7\n",
      "13   daily  high       8\n",
      "14   daily  high       7\n",
      "15  weekly   low       3\n",
      "16  weekly   low       4\n",
      "17  weekly   low       4\n",
      "18  weekly   low       4\n",
      "19  weekly   low       5\n",
      "20  weekly   med       4\n",
      "21  weekly   med       4\n",
      "22  weekly   med       4\n",
      "23  weekly   med       4\n",
      "24  weekly   med       4\n",
      "25  weekly  high       5\n",
      "26  weekly  high       6\n",
      "27  weekly  high       6\n",
      "28  weekly  high       7\n",
      "29  weekly  high       8\n",
      "                   df     sum_sq    mean_sq        F    PR(>F)\n",
      "C(sun)            2.0  24.866667  12.433333  23.3125  0.000002\n",
      "C(water)          1.0   8.533333   8.533333  16.0000  0.000527\n",
      "C(sun):C(water)   2.0   2.466667   1.233333   2.3125  0.120667\n",
      "Residual         24.0  12.800000   0.533333      NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#create data\n",
    "df = pd.DataFrame({'water': np.repeat(['daily', 'weekly'], 15),\n",
    "                   'sun': np.tile(np.repeat(['low', 'med', 'high'], 5), 2),\n",
    "                   'height': [6, 6, 6, 5, 6, 5, 5, 6, 4, 5, 6, 6, 7, 8, 7, 3, 4, 4, 4, 5, 4, 4, 4, 4, 4, 5, 6, 6, 7, 8]})    \n",
    "    \n",
    "print(df)\n",
    "model = ols('height ~ C(sun) + C(water) + C(sun):C(water)',data=df).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1607900-1614-4493-b198-58b0fb531c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance value = 0.05\n",
    "\n",
    "We can see the following p-values for each of the factors:\n",
    "water: p-value = 0.000527\n",
    "sun: p-value = 0.0000002\n",
    "water*sun: p-value = 0.120667\n",
    "\n",
    "Main effects: Since the p-values for water and sun are both less than 0.05, this means that both factors have a \n",
    "statistically significant effect on plant height.\n",
    "\n",
    "Interaction effects: Since the p-value for the interaction effect (0.120667) is not less than 0.05, this tells\n",
    "us that there is no significant interaction effect between sunlight exposure and watering frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e25bcf-30d7-4923-9a87-f4e25f542425",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fccd15-6245-4749-aeaa-227f21a86022",
   "metadata": {},
   "outputs": [],
   "source": [
    "F-statistic = 5.23 > 1\n",
    "This means variation between the samples is much greater than the variation within the samples.\n",
    "A big F(5.23), with a small p-value(0.02), means that the null hypothesis is discredited(refuse to accept), and\n",
    "we would assert that the means are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283866da-6a81-4835-8846-30f296f7739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf8117-303e-43c9-a843-e47b0182e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "When dealing with missing data, we can use two primary methods to solve the error:\n",
    "\n",
    "The imputation method: substitutes reasonable guesses for missing data. It’s most useful when \n",
    "the percentage of missing data is low. If the portion of missing data is too high, the results\n",
    "lack natural variation that could result in an effective model.\n",
    "There are examples of single imputation methods for replacing missing data.\n",
    "\n",
    "1. Mean, Median and Mode: In cases where there are a small number of missing observations, we can calculate\n",
    "the mean or median of the existing observations and insert them in place of the missing observations.\n",
    "\n",
    "2. Time-Series Specific Methods: of imputation assume the adjacent observations will be like the missing data. \n",
    "\n",
    "3. Last Observation Carried Forward (LOCF) & Next Observation Carried Backward (NOCB): Every missing value\n",
    "is replaced with either the last observed value or the next one.\n",
    "\n",
    "4. Linear Interpolation: is often used to approximate a value of some function by using two known values\n",
    "of that function at other points. This formula can also be understood as a weighted average. \n",
    "\n",
    "The other option is to remove data. When dealing with data that is missing at random(the data is \n",
    "not missing across all observations but only within sub-samples of the data.), the entire\n",
    "data point that is missing information can be deleted to help reduce bias. Removing data may not\n",
    "be the best option if there are not enough observations to result in a reliable analysis. In some \n",
    "situations, observation of specific events or factors may be required, even if incomplete.\n",
    "\n",
    "Consequences: If we use proc glm to perform the analysis, it will omit observations listwise, meaning \n",
    "that if any of the observations for a subject are missing, the entire subject will be omitted from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77de9c5-9cbb-40cc-a9cd-31b4a6794532",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874a46f-1813-4850-855a-5694059b9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "When a one-way ANOVA test leads to a significant result, it is common to then follow up with post-hoc\n",
    "tests to see which particular groups are significantly different from each other. Post-hoc tests \n",
    "essentially involve carrying out multiple t -tests to test for differences between each pair of categories.\n",
    "\n",
    "Some common post hoc tests include:\n",
    "Tukey's HSD: A commonly used pairwise multiple comparison test\n",
    "Scheffe's F: A commonly used pairwise multiple comparison test\n",
    "Bonferroni: A simple post hoc test that tightens the criterion for accepting an effect as significant\n",
    "Dunnett's: A multiple comparison test\n",
    "Hsu's MCB: Useful when we don't know which group to compare to all the other groups\n",
    "Tamhane's T2: A multiple comparison test that doesn't assume equal variances\n",
    "Dunnett's T3: A multiple comparison test that doesn't assume equal variances\n",
    "Games-Howell: A multiple comparison test that doesn't assume equal variances \n",
    "\n",
    "Post hoc tests are used when the null hypothesis of an ANOVA model is rejected. For example, if an ANOVA \n",
    "shows that three influencer types have different effectiveness, a post hoc test could reveal that Instagram \n",
    "influencers are more effective than TikTok and Facebook influencers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9869e4-0e24-4930-a4ed-8810355044c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d65c94b-9b78-4aa1-8a59-609c38fad9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 26.402206764783106 and P-value: 1.5971692021748323e-10\n",
      "Reject the null hypothesis as there will be at least one population mean that differs from the rest\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "diet_A = np.random.normal(loc=47, scale=5,size = 50)\n",
    "diet_B = np.random.normal(loc=50, scale=5,size = 50)\n",
    "diet_C = np.random.normal(loc=55, scale=5,size = 50)\n",
    "\n",
    "null_hypothesis =  'μA = μB = μC (It implies that the means of all the population are equal)'\n",
    "alternate_hypothesis = 'as there will be at least one population mean that differs from the rest'\n",
    "significance_value = 0.05\n",
    "\n",
    "# Conduct the one-way ANOVA\n",
    "F_statistic,p_value = st.f_oneway(diet_A,diet_B,diet_C)\n",
    "print('F-statistic:',F_statistic,'and P-value:',p_value)\n",
    "\n",
    "if p_value > significance_value:\n",
    "    print('Accept the null hypothesis',null_hypothesis)\n",
    "else:\n",
    "    print('Reject the null hypothesis',alternate_hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712e552-f2fb-427c-90ba-4ecb61329cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis of result: The F statistic and p-value turn out to be equal to 21.575416756474326 and 6.08280571508745e-09\n",
    "respectively. Since the p-value is less than 0.05 hence we would reject the null hypothesis. This implies that we have\n",
    "sufficient proof to say that the means of all the population are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14041054-5ba6-464b-8865-ba1964a80848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9010c902-79ad-4786-8bcc-8cf67ab9841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experience_level programs       time\n",
      "0            Novice        C  13.292774\n",
      "1       Experienced        C  29.434141\n",
      "2            Novice        C  20.919417\n",
      "3            Novice        A  20.500477\n",
      "4       Experienced        A  19.548862\n",
      "..              ...      ...        ...\n",
      "85      Experienced        A   9.150612\n",
      "86           Novice        C  11.232653\n",
      "87           Novice        B  17.275389\n",
      "88      Experienced        A  24.859113\n",
      "89           Novice        C  19.845209\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "                                   df       sum_sq    mean_sq         F  \\\n",
      "C(experience_level)               1.0    98.772362  98.772362  3.687306   \n",
      "C(programs)                       2.0     3.540949   1.770474  0.066094   \n",
      "C(experience_level):C(programs)   2.0    99.247766  49.623883  1.852526   \n",
      "Residual                         84.0  2250.119610  26.787138       NaN   \n",
      "\n",
      "                                   PR(>F)  \n",
      "C(experience_level)              0.058222  \n",
      "C(programs)                      0.936091  \n",
      "C(experience_level):C(programs)  0.163191  \n",
      "Residual                              NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols \n",
    "\n",
    "df = pd.DataFrame({'experience_level': np.random.choice(['Novice', 'Experienced'], size=90),\n",
    "                   'programs': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "                   'time': np.random.normal(loc=20, scale=5, size=90)})\n",
    "print(df)\n",
    "\n",
    "# Performing two-way ANOVA \n",
    "model = ols('time ~ C(experience_level) + C(programs) + C(experience_level):C(programs)', data=df).fit() \n",
    "result = sm.stats.anova_lm(model, type=2) \n",
    "  \n",
    "# Print the result \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8512089-ade8-4e3c-9635-30439492bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Interpretation:\n",
    "\n",
    "significance value = 0.05\n",
    "\n",
    "We can see the following p-values for each of the factors:\n",
    "experience_level: p-value = 0.880069\n",
    "programs: p-value = 0.566799\n",
    "experience_level*programs: p-value = 0.000078\n",
    "\n",
    "Main effects: Since the p-values for experience_level and programs are both greater than 0.05, this means that both \n",
    "factors have not statistically significant effect on time taken to complete the task.\n",
    "\n",
    "Interaction effects: Since the p-value for the interaction effect (0.000078) is less than 0.05, this tells\n",
    "us that there is significant interaction effect between experience_level and programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcfe85-1e53-48e5-ba4d-faa432ef23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f4399d-7480-4dfc-a70f-e295cee1d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_test: 18.35881164378464 p_value: 1.2920496069794455e-44\n",
      "reject the null hypothesis as there is significant difference between the teaching methods\n"
     ]
    }
   ],
   "source": [
    "# H0: μ(traditional teaching method) = μ(new teaching method)\n",
    "# H1: μ(traditional teaching method) ≠ μ(new teaching method)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "traditional_method = np.random.normal(loc=80, scale=5,size = 100)\n",
    "new_method = np.random.normal(loc=70, scale=2, size = 100)\n",
    "\n",
    "significance_value = 0.05\n",
    "t_test,p_value = st.ttest_ind(traditional_method, new_method)\n",
    "print('t_test:',t_test,'p_value:',p_value)\n",
    "\n",
    "if p_value > significance_value:\n",
    "    print('accept the null hypothesis as there is no significant difference between the teaching methods')\n",
    "else:\n",
    "    print('reject the null hypothesis as there is significant difference between the teaching methods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd5452ae-7432-404e-91d1-482c221f9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1    group2   meandiff p-adj lower  upper  reject\n",
      "------------------------------------------------------\n",
      "   New Traditional  10.1714   0.0 9.0788 11.264   True\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Post-hoc test\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "df = pd.DataFrame({'score': np.concatenate([traditional_method,new_method]), 'group': ['Traditional']*100 + ['New']*100})\n",
    "# Perform the Tukey's HSD test\n",
    "tukey_results = pairwise_tukeyhsd(df['score'], df['group'])\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b347d07-7381-4c2f-9027-9af044866128",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences\n",
    "in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine\n",
    "which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a851f2b5-3e15-4b64-a36b-e3bcce9e5ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 15.169539048126635 and P-value: 2.2301355860658083e-06 \n",
      "\n",
      "Reject the null hypothesis as there is significant difference in the average daily sales of 3 retail stores.\n"
     ]
    }
   ],
   "source": [
    "# H0: μ1 = μ2 = μ3\n",
    "# H1: at least one of the means is different from the others\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "store_a=np.random.normal(loc=900, scale=200, size=30)\n",
    "store_b=np.random.normal(loc=1000, scale=100, size=30)\n",
    "store_c=np.random.normal(loc=800, scale=100, size=30)\n",
    "\n",
    "# Conduct the repeated measures ANOVA \n",
    "F_statistic, p_value = stats.f_oneway(store_a, store_b, store_c)\n",
    "print('F-statistic:',F_statistic,'and P-value:',p_value,'\\n')\n",
    "\n",
    "significance_value = 0.05\n",
    "if p_value < significance_value:\n",
    "    print('Reject the null hypothesis as there is significant difference in the average daily sales of 3 retail stores.')\n",
    "else:\n",
    "    print('Accept the null hypothesis as there is no significant difference in the average daily sales of 3 retail stores.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3eb2c77-f093-49a7-8388-eb29ead83d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      "group1 group2  meandiff p-adj    lower     upper   reject\n",
      "---------------------------------------------------------\n",
      "     A      B   96.0246 0.0313    7.0159  185.0333   True\n",
      "     A      C -109.4376 0.0119 -198.4463  -20.4288   True\n",
      "     B      C -205.4622    0.0 -294.4709 -116.4535   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Post-hoc test\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "df = pd.DataFrame({'sales': np.concatenate([store_a,store_b,store_c]), 'group': ['A']*30 + ['B']*30 + ['C']*30})\n",
    "# Perform the Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(df['sales'], df['group'])\n",
    "print(tukey)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
